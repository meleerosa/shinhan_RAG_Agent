import os
import json
import faiss
from typing import TypedDict, List, Optional, Any
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage
from langgraph.graph import StateGraph, END
from langchain_community.vectorstores import FAISS
import datetime


# ==========================================
# ë¡œê·¸ ì €ì¥ ìœ í‹¸ë¦¬í‹°
# ==========================================
LOG_DIR = "/home/wlaud/projects/shinhan/logs"


def save_session_log(final_state: dict):
    """ì„¸ì…˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ìƒì„¸ ì €ì¥ (ëª¨ë“  ì •ë³´ í¬í•¨)"""
    
    # 1. ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
    if not os.path.exists(LOG_DIR):
        try:
            os.makedirs(LOG_DIR)
        except Exception as e:
            print(f"[Log Error] í´ë” ìƒì„± ì‹¤íŒ¨: {e}")
            return


    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{LOG_DIR}/agent_log_{timestamp}.json"
    
    # 2. ì €ì¥í•  ë°ì´í„° êµ¬ì¡°í™” (Full Detail)
    log_data = {
        "timestamp": timestamp,
        "user_query": final_state.get("user_query"),
        
        # [1] í”„ë¡œí•„ ë¶„ì„ ê²°ê³¼
        "final_profile": final_state.get("profile"),
        "missing_info": final_state.get("missing_info"),
        "ask_count": final_state.get("ask_count"),
        
        # [2] ê²€ìƒ‰ ê²°ê³¼ (ì „ì²´ ë°ì´í„° ì›ë³¸ ì €ì¥)
        "candidates_count": len(final_state.get("candidates", [])),
        "candidates": final_state.get("candidates", []), 
        
        # [3] ë¹„í‰(Critic) ë¦¬í¬íŠ¸
        "critic_report": final_state.get("critic_report"),
        
        # [4] ìµœì¢… ë‹µë³€
        "final_response": final_state.get("final_response"),
        
        # [5] ì „ì²´ ì‚¬ê³  ê³¼ì • (íƒ€ì„ë¼ì¸)
        "thinking_process": final_state.get("thinking_process", [])
    }
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, ensure_ascii=False, indent=2)
        # print(f"[Log Saved] {filename}") 
    except Exception as e:
        print(f"[Log Error] ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")



# ==========================================
# 0. API ì„¤ì •
# ==========================================
if "OPENAI_API_KEY" not in os.environ:
    print("Error: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” exit(1) ëŒ€ì‹  ê²½ê³ ë§Œ í•˜ê±°ë‚˜ ì˜ˆì™¸ì²˜ë¦¬
    pass 


llm = ChatOpenAI(model="gpt-4o", temperature=0)
embeddings = OpenAIEmbeddings()


# ==========================================
# 1. ë°ì´í„° ë¡œë“œ & FAISS êµ¬ì¶• (Max Info Version)
# ==========================================
json_path = "/home/wlaud/projects/shinhan/data/sample_extracted_200.json"


if not os.path.exists(json_path):
    print("Error: ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. extract_sample_json.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    raw_data = [] 
else:
    with open(json_path, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)


documents = []
metadatas = []


print(f">>> ì´ {len(raw_data)}ê°œ ì›ë³¸ ë°ì´í„° ë¡œë“œ ë° ë²¡í„°í™” ì‹œì‘")


for item in raw_data:
    if "error" in item: continue
    
    # [ë°ì´í„° Flattening] ëª¨ë“  ìƒì„¸ ì •ë³´ë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
    idx_info = f"ìƒí’ˆëª…: {item.get('product_name')} / ì¹´í…Œê³ ë¦¬: {item.get('category')}"
    
    specs = []
    if item.get('interest_rate'):
        ir = item.get('interest_rate', {})
        specs.append(f"ê¸°ë³¸ê¸ˆë¦¬ {ir.get('base_rate')}% ìµœê³ ê¸ˆë¦¬ {ir.get('max_rate')}%")
        if ir.get('prime_conditions'): specs.append(f"ìš°ëŒ€ì¡°ê±´: {', '.join(ir.get('prime_conditions'))}")
    elif item.get('base_interest_rate'):
        specs.append(f"ê¸°ë³¸ê¸ˆë¦¬ {item.get('base_interest_rate')}%")
    
    elig = item.get('eligibility', {})
    if isinstance(elig, dict):
        specs.append(f"ê°€ì…ëŒ€ìƒ: {elig.get('target_detail', 'ëˆ„êµ¬ë‚˜')}")
        if elig.get('age_min'): specs.append(f"ìµœì†Œì—°ë ¹ {elig.get('age_min')}ì„¸")
        if elig.get('age_max'): specs.append(f"ìµœëŒ€ì—°ë ¹ {elig.get('age_max')}ì„¸")


    features = []
    join = item.get('join_channel')
    if isinstance(join, dict):
        if join.get('is_online'): features.append("ë¹„ëŒ€ë©´ ì•± ê°€ì… ê°€ëŠ¥")
        if join.get('is_offline'): features.append("ì˜ì—…ì  ë°©ë¬¸ í•„ìˆ˜")
        features.extend(join.get('descriptions', []))
    
    if item.get('accumulation_type'): features.append(item.get('accumulation_type')) 
    if item.get('max_deposit'): features.append(f"ì›”ë‚©ì…í•œë„ {item.get('max_deposit')}ì›")
    if item.get('partial_withdrawal'): features.append("ê¸´ê¸‰ì¶œê¸ˆ ê°€ëŠ¥")
    
    if item.get('risk_grade'): features.append(f"ìœ„í—˜ë“±ê¸‰ {item.get('risk_grade')}ë“±ê¸‰")
    if item.get('principal_protected') is False: features.append("ì›ê¸ˆë¹„ë³´ì¥ ì†ì‹¤ìœ„í—˜")
    if item.get('interest_payment_date'): features.append("ë§¤ì¼/ë§¤ì›” ì´ìì§€ê¸‰ íŒŒí‚¹í†µì¥")
    
    risk_info = item.get('risk_caution') or item.get('loss_warning') or ""
    summary = item.get('summary', '')


    full_text = f"""
    {idx_info}
    [ìŠ¤í™] {' | '.join(specs)}
    [íŠ¹ì§•] {' | '.join(features)}
    [ìš”ì•½] {summary}
    [ì£¼ì˜] {risk_info}
    """
    
    documents.append(full_text.strip())
    metadatas.append(item)


if documents:
    vectorstore = FAISS.from_texts(documents, embeddings, metadatas)
    print(">>> FAISS Vector Store êµ¬ì¶• ì™„ë£Œ")
else:
    print("Error: ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨")
    # exit(1) # í…ŒìŠ¤íŠ¸ í™˜ê²½ ê³ ë ¤í•˜ì—¬ ì£¼ì„ ì²˜ë¦¬


# ==========================================
# 2. State ì •ì˜ (Thinking Process ì¶”ê°€)
# ==========================================
class UserProfile(TypedDict):
    age: Optional[int]
    job: Optional[str]
    category: Optional[str]
    financial_goal: Optional[str]
    investment_period: Optional[str]
    monthly_amount: Optional[str]
    risk_tolerance: Optional[str]


class AgentState(TypedDict):
    messages: List[BaseMessage]
    user_query: str
    profile: UserProfile
    missing_info: List[str]
    ask_count: int
    candidates: List[dict]
    critic_report: str
    final_response: str
    # [ì¶”ê°€] ë””ë²„ê¹… ë¡œê·¸ìš©
    thinking_process: List[str]


# ==========================================
# 3. í—¬í¼ í•¨ìˆ˜ (ë¡œê·¸ ê¸°ë¡)
# ==========================================
def log_step(state: AgentState, step_name: str, content: str) -> List[str]:
    """Thinking Processì— ë¡œê·¸ë¥¼ ì¶”ê°€í•˜ê³  ë°˜í™˜"""
    logs = state.get("thinking_process") or [] # None ë°©ì§€
    log_entry = f"[{step_name}] {content}"
    # print(f"\nğŸ‘‰ {log_entry}") # ì‹¤ì‹œê°„ í™•ì¸ìš© ì¶œë ¥
    return logs + [log_entry]


# ==========================================
# 4. Node êµ¬í˜„ (High-End PB Version)
# ==========================================


# --- Node 1: Profile (ì‹¬ì¸µ í”„ë¡œíŒŒì¼ë§) ---
def profile_node(state: AgentState):
    print("\n[1. Profiling] ì‹¬ì¸µ ë¶„ì„ ì¤‘...")
    
    history_text = "\n".join([f"{m.type}: {m.content}" for m in state["messages"]])
    full_context = f"{history_text}\nUser(Current): {state['user_query']}"
    current_profile = state["profile"]
    ask_count = state.get("ask_count", 0)
    
    system_prompt = f"""
    ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë² í…Œë‘ ê¸ˆìœµ PBì…ë‹ˆë‹¤. ëŒ€í™” ë§¥ë½ì—ì„œ ì•„ë˜ 7ê°€ì§€ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
    
    [ì¶”ì¶œ í•­ëª©]
    1. age: ë‚˜ì´ (ìˆ«ì)
    2. job: ì§ì—…
    3. category: [Savings(ì˜ˆì ê¸ˆ), Investment(íˆ¬ì), Demand(ì…ì¶œê¸ˆ), Insurance(ë³´í—˜), Pension(ì—°ê¸ˆ)]
    4. financial_goal: ìê¸ˆ ëª©ì  (ê²°í˜¼, ì£¼íƒ, ë…¸í›„ ë“±)
    5. investment_period: íˆ¬ì/ì˜ˆì¹˜ ê¸°ê°„
    6. monthly_amount: ì›” ë‚©ì…/ê°€ìš© ê¸ˆì•¡ (ì˜ˆ: '50ë§Œì›')
    7. risk_tolerance: [ì•ˆì „ì§€í–¥, ìˆ˜ìµì§€í–¥] ì¤‘ í•˜ë‚˜
       - 'ìˆ˜ìµë¥  ë†’ì€ê±°', 'ëˆ ë¶ˆë¦¬ê¸°' -> 'ìˆ˜ìµì§€í–¥'
       - 'ì•ˆì „í•œê±°', 'ì›ê¸ˆë³´ì¥' -> 'ì•ˆì „ì§€í–¥'
    
    ê¸°ì¡´ ì •ë³´: {json.dumps(current_profile, ensure_ascii=False)}
    JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”.
    """
    
    try:
        response = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=full_context)])
        extracted = json.loads(response.content.replace("```json", "").replace("```", "").strip())
        
        for k, v in extracted.items():
            if v is not None: current_profile[k] = v
            
        missing = []
        if ask_count < 2: # ìµœëŒ€ 2ë²ˆë§Œ ë˜ë¬»ê¸°
            if not current_profile.get("category"): 
                missing.append("category (ìƒí’ˆ ì¢…ë¥˜)")
            else:
                if not current_profile.get("investment_period"): missing.append("investment_period (ê¸°ê°„)")
                if not current_profile.get("monthly_amount"): missing.append("monthly_amount (ê¸ˆì•¡)")
                if current_profile.get("category") == "Investment" and not current_profile.get("risk_tolerance"):
                    missing.append("risk_tolerance (íˆ¬ìì„±í–¥)")
        
        # [Log] í”„ë¡œí•„ ì¶”ì¶œ ê²°ê³¼
        new_logs = log_step(state, "1. Profiling", f"ì¶”ì¶œëœ ì •ë³´: {extracted}, ë¶€ì¡± ì •ë³´: {missing}")
        
        return {
            "profile": current_profile, 
            "missing_info": missing, 
            "ask_count": ask_count,
            "thinking_process": new_logs
        }
    except Exception as e:
        new_logs = log_step(state, "1. Profiling Error", str(e))
        return {"missing_info": [], "thinking_process": new_logs}


# --- Node 2: AskMore (ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸) ---
def ask_more_node(state: AgentState):
    print("\n[2. AskMore] ì •ë³´ ë³´ê°• ìš”ì²­...")
    missing = state["missing_info"]
    prompt = f"""
    ì‚¬ìš©ìì—ê²Œ ê¸ˆìœµ ìƒí’ˆ ì¶”ì²œì„ ìœ„í•´ í•„ìš”í•œ ì •ë³´ {missing}ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”.
    ë‹¨, ê¸°ê³„ì ìœ¼ë¡œ ë¬»ì§€ ë§ê³  "{missing}ì„ ì•Œë ¤ì£¼ì‹œë©´ ìˆ˜ìµì„±ì´ ê°€ì¥ ë†’ì€ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ìˆì–´ìš”" ì²˜ëŸ¼ ì´ìœ ë¥¼ ë§ë¶™ì´ì„¸ìš”.
    """
    response = llm.invoke([SystemMessage(content=prompt)])
    
    # [Log] ì¬ì§ˆë¬¸ ìƒì„±
    new_logs = log_step(state, "2. AskMore", f"ìš”ì²­ ì •ë³´: {missing} -> ì§ˆë¬¸: {response.content}")
    
    return {
        "final_response": response.content, 
        "ask_count": state["ask_count"] + 1,
        "thinking_process": new_logs
    }


# --- Node 3: Retrieve (ê²€ìƒ‰ì–´ í™•ì¥ & ë§¤í•‘) ---
def retrieve_node(state: AgentState):
    print("\n[3. Retrieving] ì •ë°€ ë§¤ì¹­ ê²€ìƒ‰ ì¤‘...")
    profile = state["profile"]
    query = state["user_query"]
    
    # [Mapping Strategy]
    keywords = []
    
    if profile.get("category"): keywords.append(profile.get("category"))
    if profile.get("risk_tolerance") == "ì•ˆì „ì§€í–¥": keywords.append("ì›ê¸ˆë³´ì¥ ì˜ˆê¸ˆìë³´í˜¸ ì•ˆì •í˜•")
    elif profile.get("risk_tolerance") == "ìˆ˜ìµì§€í–¥": keywords.append("ê³ ìˆ˜ìµ ì‹¤ì ë°°ë‹¹ ìœ„í—˜í˜•")
    
    if "ì•±" in query or "í°" in query: keywords.append("ë¹„ëŒ€ë©´ ì˜¨ë¼ì¸")
    if "ì§€ì " in query or "ì°½êµ¬" in query: keywords.append("ì˜ì—…ì ")
    if "ììœ " in query or "ì•„ë¬´ë•Œë‚˜" in query: keywords.append("ììœ ì ë¦½ì‹")
    if "ë§¤ì¼" in query: keywords.append("ì´ìì§€ê¸‰ì¼ ë§¤ì¼") 


    final_query = f"{' '.join(keywords)} {query}"
    # print(f" -> ê²€ìƒ‰ ì¿¼ë¦¬: {final_query}")
    
    docs_and_scores = vectorstore.similarity_search_with_score(final_query, k=30)
    candidates = []
    
    for doc, score in docs_and_scores:
        p = doc.metadata
        
        # [Strict Filter]
        if profile.get("category") and profile.get("category") not in p.get('category', ''):
            continue
            
        # [Eligibility Filter]
        age = profile.get("age")
        elig = p.get('eligibility')
        if age and isinstance(elig, dict):
            if elig.get('age_min') and age < elig.get('age_min'): continue
            if elig.get('age_max') and age > elig.get('age_max'): continue
        
        candidates.append(p)
        if len(candidates) >= 3: break
    
    # Fallback
    fallback_used = False
    if not candidates and profile.get("category"):
        # print(" -> [Info] ìƒì„¸ ì¡°ê±´ ë§¤ì¹­ ì‹¤íŒ¨. ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê´‘ë²”ìœ„ ê²€ìƒ‰ ì‹¤í–‰.")
        fallback_used = True
        for doc, score in docs_and_scores:
            if profile.get("category") in doc.metadata.get('category', ''):
                candidates.append(doc.metadata)
            if len(candidates) >= 2: break
            
    # [Log] ê²€ìƒ‰ ê²°ê³¼
    cand_names = [c.get('product_name') for c in candidates]
    log_msg = f"ì¿¼ë¦¬: '{final_query}', ê²°ê³¼({len(candidates)}ê±´): {cand_names}"
    if fallback_used: log_msg += " (Fallback ì‚¬ìš©ë¨)"
    new_logs = log_step(state, "3. Retrieval", log_msg)
    
    return {
        "candidates": candidates,
        "thinking_process": new_logs
    }


# --- Node 4: Critic (ìˆ˜ìµ ì‹œë®¬ë ˆì´ì…˜ & ìŠ¤í™ ê²€ì¦) ---
def critic_node(state: AgentState):
    print("\n[4. Critical Thinking] ìˆ˜ìµì„± ë° ì í•©ì„± ì‹œë®¬ë ˆì´ì…˜...")
    candidates = state["candidates"]
    profile = state["profile"]
    
    if not candidates: 
        new_logs = log_step(state, "4. Critic", "í›„ë³´ ìƒí’ˆ ì—†ìŒ")
        return {
            "critic_report": "No candidates found.",
            "thinking_process": new_logs
        }


    prompt = f"""
    ë‹¹ì‹ ì€ ê³ ê° ìì‚° ì¦ì‹ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ëŠ” PBì…ë‹ˆë‹¤.
    í›„ë³´ ìƒí’ˆì„ ë¶„ì„í•˜ì—¬ ì˜ˆìƒ ìˆ˜ìµì„ ê³„ì‚°í•˜ê³ , ë¶€ì í•©í•œ ìš”ì†Œë¥¼ ì°¾ì•„ë‚´ì„¸ìš”.
    
    [ê³ ê° í”„ë¡œí•„]
    - ì›” ë‚©ì…ê¸ˆ: {profile.get('monthly_amount', 'ë¯¸ì •')}
    - ê¸°ê°„: {profile.get('investment_period', 'ë¯¸ì •')}
    - ì„±í–¥: {profile.get('risk_tolerance', 'ë¯¸ì •')}
    
    [í›„ë³´ ìƒí’ˆ]
    {json.dumps(candidates, ensure_ascii=False, indent=2)}
    
    [ë¶„ì„ ìš”êµ¬ì‚¬í•­]
    1. **ìˆ˜ìµ ì‹œë®¬ë ˆì´ì…˜ (í•„ìˆ˜)**: 
       - ê³ ê°ì´ ì›” ë‚©ì…ê¸ˆì„ ê¸°ê°„ ë™ì•ˆ ë‚©ì…í–ˆì„ ë•Œ, **ë§Œê¸° ì˜ˆìƒ ìˆ˜ë ¹ì•¡(ì„¸í›„)**ì„ ê³„ì‚°í•´ ì£¼ì„¸ìš”. (ì´ìì†Œë“ì„¸ 15.4% ì°¨ê°)
       - ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ "ì•½ 00% ê¸ˆë¦¬ ì ìš© ì‹œ"ë¼ê³  ê°€ì •í•˜ì—¬ ê³„ì‚°í•˜ì„¸ìš”.
       - ê³„ì‚° ê³¼ì •ì„ ìì„¸íˆ ì‘ì„±í•˜ì„¸ìš”.
    2. **í•œë„ ê²€ì¦**: 
       - ì›” ë‚©ì…ê¸ˆì´ ìƒí’ˆì˜ 'max_deposit'ì„ ì´ˆê³¼í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì´ˆê³¼ ì‹œ **"í•œë„ ì´ˆê³¼! ë¶„ì‚° íˆ¬ì í•„ìš”"** ê²½ê³  í•„ìˆ˜.
    3. **ê°€ì… í¸ì˜ì„±**: 
       - 'join_channel'ì„ í™•ì¸í•˜ì—¬ ê°€ì… ê°€ëŠ¥í•œ ë°©ì•ˆ ì‘ì„±í•˜ì„¸ìš”.
    4. **ë¦¬ìŠ¤í¬**: 
       - ì›ê¸ˆ ì†ì‹¤ ê°€ëŠ¥ì„±, ì¤‘ë„í•´ì§€ ë¶ˆì´ìµ ë“±ì„ ì°¾ì•„ë‚´ì„¸ìš”.
    
    ìœ„ ë‚´ìš©ì„ í¬í•¨í•œ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    """
    response = llm.invoke([SystemMessage(content=prompt)])
    
    # [ìˆ˜ì •ë¨] ë¡œê·¸ì— ì‹¤ì œ ë¦¬í¬íŠ¸ ë‚´ìš© í¬í•¨
    new_logs = log_step(state, "4. Critic", f"ë¶„ì„ ë¦¬í¬íŠ¸ ê²°ê³¼:\n{response.content}")
    
    return {
        "critic_report": response.content,
        "thinking_process": new_logs
    }


# --- Node 5: Response (ìƒì„¸ ì •ë³´ ì œê³µ & í–‰ë™ ìœ ë„) ---
def response_node(state: AgentState):
    print("\n[5. Response] ìµœì¢… ì œì•ˆì„œ ì‘ì„± ì¤‘...")
    report = state.get("critic_report", "No candidates found.")
    candidates = state.get("candidates", [])
    profile = state["profile"]
    
    if report == "No candidates found.":
        new_logs = log_step(state, "5. Response", "ìƒí’ˆ ì—†ìŒ ì•ˆë‚´")
        return {
            "final_response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            "thinking_process": new_logs
        }


    # [Data Injection] ì›ë³¸ ë°ì´í„°ì˜ ë””í…Œì¼ì„ ë³´ê¸° ì¢‹ê²Œ ê°€ê³µ
    product_details = ""
    for idx, item in enumerate(candidates, 1):
        join = item.get('join_channel')
        if isinstance(join, dict): 
            join_str = ", ".join(join.get('descriptions', [])) or ("ì•± ê°€ì… ê°€ëŠ¥" if join.get('is_online') else "ì˜ì—…ì  ë°©ë¬¸")
        else: join_str = str(join)
        
        rate_info = item.get('interest_rate')
        if isinstance(rate_info, dict):
            rate_str = f"ìµœê³  ì—° {rate_info.get('max_rate')}% (ê¸°ë³¸ {rate_info.get('base_rate')}%)"
            rate_cond = f"\n   â”” ìš°ëŒ€ì¡°ê±´: {', '.join(rate_info.get('prime_conditions', []))}" if rate_info.get('prime_conditions') else ""
        else:
            rate_str = str(rate_info or item.get('base_interest_rate', 'ìƒì„¸ì„¤ëª… ì°¸ì¡°'))
            rate_cond = ""


        product_details += f"""
        [{idx}. {item.get('product_name')}]
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        ğŸ’° ê¸ˆë¦¬/ìˆ˜ìµ: {rate_str}{rate_cond}
        ğŸ“… ê¸°ê°„/í•œë„: {item.get('min_month', 0)}~{item.get('max_month', 0)}ê°œì›” / ì›” {item.get('max_deposit', 'ì œí•œì—†ìŒ')}ì›
        ğŸ“± ê°€ì…ë°©ë²•: {join_str}
        ğŸ“ íŠ¹ì§•: {item.get('accumulation_type', '')} {item.get('summary', '')}
        âš ï¸ ì£¼ì˜: {item.get('risk_caution', item.get('loss_warning', 'ì—†ìŒ'))}
        """


    prompt = f"""
    ë‹¹ì‹ ì€ ê³ ê°ì˜ ì„±ê³µì ì¸ ìì‚° ê´€ë¦¬ë¥¼ ë•ëŠ” AI PBì…ë‹ˆë‹¤.
    ì „ë¬¸ì ì¸ ë¶„ì„ ê²°ê³¼ì™€ ìƒì„¸ ìƒí’ˆ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„¤ë“ë ¥ ìˆëŠ” ì œì•ˆì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    
    [Critic ë¶„ì„ ê²°ê³¼]
    {report}
    
    [ìƒí’ˆ ìƒì„¸ ìŠ¤í™]
    {product_details}
    
    [ë‹µë³€ êµ¬ì¡° ê°€ì´ë“œ]
    ### 1. ğŸ† AI PBì˜ ì›í”½ ì¶”ì²œ
    *   "ê³ ê°ë‹˜ì˜ ìƒí™©(ëª©ì , ê¸ˆì•¡)ì—ëŠ” **[ìƒí’ˆëª…]**ì´ ê°€ì¥ ìœ ë¦¬í•©ë‹ˆë‹¤." ë¡œ ì‹œì‘.
    *   ì¶”ì²œ ì´ìœ ë¥¼ í•µì‹¬ë§Œ ìš”ì•½.
    
    ### 2. ğŸ’¸ ë¨¸ë‹ˆ ì‹œë®¬ë ˆì´ì…˜ (ì˜ˆìƒ ìˆ˜ìµ)
    *   "ë§¤ì›” {profile.get('monthly_amount', '00')}ì›ì”© ë‚©ì… ì‹œ..."
    *   Criticì´ ê³„ì‚°í•œ **ê³„ì‚° ê³¼ì •ê³¼ ë§Œê¸° ì˜ˆìƒ ìˆ˜ë ¹ì•¡**ì„ ëª…ì‹œ.
    
    ### 3. ğŸ” ìƒí’ˆ ìƒì„¸ ì •ë³´
    *   ìœ„ [ìƒí’ˆ ìƒì„¸ ìŠ¤í™] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì´ ì•Œì•„ì•¼ í•  í•µì‹¬ ì •ë³´(ìš°ëŒ€ê¸ˆë¦¬ ì¡°ê±´, ê°€ì…ë°©ë²• ë“±)ë¥¼ ì •ë¦¬.
    
    ### 4. ğŸ’¡ ì†”ì§í•œ ì¡°ì–¸ (Risk & Tip)
    *   í•œë„ê°€ ë¶€ì¡±í•˜ë‹¤ë©´ **"í’ì°¨ëŒë¦¬ê¸°"**ë‚˜ **"ë¶„ì‚° íˆ¬ì"** ì œì•ˆ.
    *   ë¦¬ìŠ¤í¬ë‚˜ ê¹Œë‹¤ë¡œìš´ ìš°ëŒ€ì¡°ê±´ì´ ìˆë‹¤ë©´ ë¯¸ë¦¬ ê³ ì§€.
    
    ### 5. ğŸš€ ê°€ì… ë°”ë¡œê°€ê¸°
    *   ê°€ì… ì±„ë„(ì•±/ì˜ì—…ì )ì— ë”°ë¥¸ êµ¬ì²´ì  í–‰ë™ ì§€ì¹¨ ì œì‹œ.
    """
    response = llm.invoke([SystemMessage(content=prompt)])
    
    # [ìˆ˜ì •ë¨] ë¡œê·¸ì— ì‹¤ì œ ìƒì„±ëœ ë‹µë³€ ë‚´ìš© í¬í•¨
    new_logs = log_step(state, "5. Response", f"ìƒì„±ëœ ë‹µë³€:\n{response.content}")
    
    return {
        "final_response": response.content,
        "thinking_process": new_logs
    }


# ==========================================
# 5. Graph êµ¬ì„±
# ==========================================
workflow = StateGraph(AgentState)
workflow.add_node("profile", profile_node)
workflow.add_node("ask_more", ask_more_node)
workflow.add_node("retrieve", retrieve_node)
workflow.add_node("critic", critic_node)
workflow.add_node("response", response_node)


def route_after_profile(state):
    # ì •ë³´ê°€ ë¶€ì¡±í•˜ê³  && ì§ˆë¬¸ íšŸìˆ˜ê°€ 2íšŒ ë¯¸ë§Œì¼ ë•Œë§Œ ask_more
    if state["missing_info"] and state["ask_count"] < 2: return "ask_more"
    return "retrieve"


def route_after_retrieve(state):
    if not state["candidates"]: return "response"
    return "critic"


workflow.set_entry_point("profile")
workflow.add_conditional_edges("profile", route_after_profile)
workflow.add_edge("ask_more", END)
workflow.add_conditional_edges("retrieve", route_after_retrieve)
workflow.add_edge("critic", "response")
workflow.add_edge("response", END)


app = workflow.compile()


# ==========================================
# 6. ì‹¤í–‰ ë£¨í”„
# ==========================================
def start_chat():
    print("="*60)
    print("ğŸ¤– AI PBì™€ ìƒë‹´ì„ ì‹œì‘í•©ë‹ˆë‹¤. (ì¢…ë£Œ: q)")
    print("   Tip: ì›í•˜ì‹œëŠ” íˆ¬ì ìƒí’ˆ, ì„±í–¥, ìê¸ˆ ëª©ì  ë“± ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ì •í™•ë„ê°€ ì˜¬ë¼ê°‘ë‹ˆë‹¤.")
    print("="*60)
    
    history = []
    curr_profile = {"age": None, "job": None, "category": None, 
                   "financial_goal": None, "investment_period": None, 
                   "monthly_amount": None, "risk_tolerance": None}
    curr_ask_count = 0 
    
    while True:
        q = input("\nUser: ").strip()
        if q.lower() == 'q': break
        
        inputs = {
            "messages": history, "user_query": q, "profile": curr_profile,
            "ask_count": curr_ask_count, "missing_info": [], "candidates": [],
            "thinking_process": [] # ì´ˆê¸°í™”
        }
        res = app.invoke(inputs)
        ans = res['final_response']
        print(f"\nAI: {ans}")
        save_session_log(res)
        # ë””ë²„ê¹…: Thinking Process ì¶œë ¥


        
        history.append(HumanMessage(content=q))
        history.append(SystemMessage(content=ans))
        if "profile" in res: curr_profile = res["profile"]
        if "ask_count" in res: curr_ask_count = res["ask_count"]


if __name__ == "__main__":
    start_chat()
